<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Biomarker prediction in cancer data</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       </style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>


<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="/home/adam/R/x86_64-pc-linux-gnu-library/4.4/BiocStyle/resources/html/bioconductor.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 828px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {

}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 246px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



<script>
function toggle_visibility(id1) {
  var e = document.getElementById(id1);
  e.style.display = ((e.style.display!="none") ? "none" : "block");
}
</script>

</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Biomarker Discovery in cfRNA data</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="01_qa_pe.html">QA Preeclampsia</a>
</li>
<li>
  <a href="02_de_pe.html">DE Preeclampsia</a>
</li>
<li>
  <a href="03_qa_cn.html">QA Cancer</a>
</li>
<li>
  <a href="04_de_cn.html">DE Cancer</a>
</li>
<li>
  <a href="05_pr_pe.html">Prediction preeclampsia</a>
</li>
<li>
  <a href="06_pr_cn.html">Prediction cancer</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Biomarker prediction in cancer data</h1>
<p class="author-name">Berta Canal Sim√≥n<span class="affil-mark">1*</span> and Adam Olivares Canal<span class="affil-mark">1**</span></p>
<p class="author-affiliation"><span class="affil-mark">1</span>Barcelona School of Economics</p>
<p class="author-email"><span class="affil-mark">*</span><a href="mailto:berta.canal@bse.eu">berta.canal@bse.eu</a><br><span class="affil-mark">**</span><a href="mailto:adam.olivares@bse.eu">adam.olivares@bse.eu</a></p>
<h4 class="date">junio 8, 2024</h4>
<h4 class="abstract">Abstract</h4>
<p>Here we perform a prediction of candidate biomarkers in cancer cfRNA sequencing data.</p>

</div>


<div id="importing-processed-and-filtered-data" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Importing processed and filtered data</h1>
<p>We start by importing the previously filtered, normalized RNA-seq data and the differential expressed genes from the training dataset.</p>
<pre class="r"><code>library(SummarizedExperiment)
library(edgeR)

dgeR.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;dgeR.filt.rds&quot;))
seR.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;seR.filt.rds&quot;))

dgeB.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;dgeB.filt.rds&quot;))
seB.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;seB.filt.rds&quot;))

dgeR.filt.training &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                        &quot;dgeR.filt.training.rds&quot;))
seR.filt.training &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                       &quot;seR.filt.training.rds&quot;))
dgeB.filt.testing &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                       &quot;dgeB.filt.testing.rds&quot;))
seB.filt.testing &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                      &quot;seB.filt.testing.rds&quot;))
DEgenes.trainingR &lt;- readRDS(file.path(&quot;_processed_data&quot;, 
                                      &quot;DEgenes.trainingR.rds&quot;))</code></pre>
<p>Create a subset with the differential expressed genes from the training dataset from <span class="citation">Roskams-Hieter et al. (<a href="#ref-Roskams2022">2022</a>)</span>.</p>
<p>Train-testing subset creation: Intersection between differential expressed genes from training set from <span class="citation">Roskams-Hieter et al. (<a href="#ref-Roskams2022">2022</a>)</span> and lowly expressed genes from testing set <span class="citation">(<a href="#ref-Block2022">Block et al. 2022</a>)</span>.</p>
<pre class="r"><code>set.seed(111)
intersection.genes &lt;- intersect(rownames(dgeB.filt.testing),DEgenes.trainingR)
length(intersection.genes)
[1] 561</code></pre>
<pre class="r"><code>
dgeR.intercept &lt;- dgeR.filt.training[intersection.genes,]
dim(dgeR.intercept)
[1] 561  58</code></pre>
<pre class="r"><code>seR.intercept &lt;- seR.filt.training[intersection.genes,]
dim(seR.intercept)
[1] 561  58</code></pre>
<pre class="r"><code>
dgeB.intercept &lt;- dgeB.filt.testing[intersection.genes,]
dim(dgeB.intercept)
[1] 561  25</code></pre>
<pre class="r"><code>seB.intercept &lt;- seB.filt.testing[intersection.genes,]
dim(seB.intercept)
[1] 561  25</code></pre>
<div id="dataframes-creation" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Dataframes creation</h2>
<div id="training-data" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Training data</h3>
<pre class="r"><code>training.df &lt;- data.frame(Tumor = seR.intercept$Tumor,
                          scale(t(assays(seR.intercept)$logCPM), scale = TRUE, center = TRUE))
len &lt;- length(training.df)</code></pre>
</div>
<div id="testing-data" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Testing data</h3>
<pre class="r"><code>testing.df &lt;- data.frame(Tumor = seB.intercept$Tumor,
                          scale(t(assays(seB.intercept)$logCPM), scale = TRUE, center = TRUE))
len &lt;- length(testing.df)</code></pre>
</div>
</div>
</div>
<div id="performance-metrics" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Performance metrics</h1>
<p>Given the application of the current paper, the False Negative Rate (FNR) metric is a particularly relevant metric, since it would imply classifying as healthy an individual with cancer. Therefore, that patients will not receive treatment, which will cause serious consequences. Furthermore, it could also be considered the False Positive Rate (FPR), which results in an undesirable situation where a proportion of healthy individuals are categorized as ill.¬†This would subject a healthy patient to unnecessary treatment and its potential side effects. However, since the expected consequences are not that severe, FNR is prioritized in the analysis.</p>
<pre class="r"><code>FNR &lt;- function(proba.pred, truth){
  class.pred &lt;- as.numeric(proba.pred &gt; 0.35)
  conf &lt;- table(truth, class.pred)
  print(conf)
  FNR &lt;- conf[2, 1] / sum(conf[2, 1], conf[2, 2])
  return(FNR)
}</code></pre>
<pre class="r"><code>FPR &lt;- function(proba.pred, truth){
  class.pred &lt;- as.numeric(proba.pred &gt; 0.35)
  conf &lt;- table(truth, class.pred)
  print(conf)
  FPR &lt;- conf[1, 2] / sum(conf[1, 1], conf[1, 2])
  return(FPR)
}</code></pre>
</div>
<div id="xgboost" class="section level1" number="3">
<h1><span class="header-section-number">3</span> XGBOOST</h1>
<pre class="r"><code>modelLookup(&quot;xgbTree&quot;)
    model        parameter                          label forReg forClass
1 xgbTree          nrounds          # Boosting Iterations   TRUE     TRUE
2 xgbTree        max_depth                 Max Tree Depth   TRUE     TRUE
3 xgbTree              eta                      Shrinkage   TRUE     TRUE
4 xgbTree            gamma         Minimum Loss Reduction   TRUE     TRUE
5 xgbTree colsample_bytree     Subsample Ratio of Columns   TRUE     TRUE
6 xgbTree min_child_weight Minimum Sum of Instance Weight   TRUE     TRUE
7 xgbTree        subsample           Subsample Percentage   TRUE     TRUE
  probModel
1      TRUE
2      TRUE
3      TRUE
4      TRUE
5      TRUE
6      TRUE
7      TRUE</code></pre>
<pre class="r"><code># CV grid search
train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,

                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

# tuning grid
set.seed(111)

xgboostGrid &lt;- expand.grid(max_depth = c(4, 5, 6, 7), nrounds = (1:10)*20,eta = c(0.2,0.4),gamma = c(0.6),subsample = c(1),min_child_weight = c(1),colsample_bytree = c(0.7))


# hyperparaemeter search for XGboost classifier tree model
model = caret::train(Tumor~., data = training.df,
              method = &quot;xgbTree&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = xgboostGrid,
              verbosity = 0,
              verbose = TRUE,
              #num.threads = 18,
              )

#print(model)</code></pre>
<pre class="r"><code>plot(model)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-10-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code># predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.7368</code></pre>
<pre class="r"><code>
FNR(pred.y, test.y)
     class.pred
truth  0  1
    0  5  1
    1  7 12
[1] 0.3684211</code></pre>
<pre class="r"><code>FPR(pred.y, test.y)
     class.pred
truth  0  1
    0  5  1
    1  7 12
[1] 0.1666667</code></pre>
<pre class="r"><code>
roc_xgboost_cn &lt;- ROCit::rocit(score=pred.y,class=test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing[1, ] &lt;- c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;XGBOOST&#39;</code></pre>
</div>
<div id="adaboost" class="section level1" number="4">
<h1><span class="header-section-number">4</span> ADABOOST</h1>
<p>Not used in the final version due to poor performance and slow training.</p>
<pre class="r"><code>modelLookup(&quot;ada&quot;)
  model parameter          label forReg forClass probModel
1   ada      iter         #Trees  FALSE     TRUE      TRUE
2   ada  maxdepth Max Tree Depth  FALSE     TRUE      TRUE
3   ada        nu  Learning Rate  FALSE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

# tuning grid
set.seed(111)
adaGrid &lt;-  expand.grid(iter = c(50), 
                        maxdepth = c(1,2),
                        nu = c(0,0.01,0.05)
                        )

#adaGrid &lt;-  expand.grid(iter = c(50, 100, 200, 500),
#                       maxdepth = c(1, 2, 3, 4, 5),
#                       nu = c(0, 0.01, 0.05, 0.1, 0.2))


# auc = 0.67, fnr=0.52, fpr=0. iter = c(50), maxdepth = c(1,2),nu = c(0,0.01,0.05))

# hyperparaemeter search for adaboost classifier tree model
model = caret::train(Tumor~., data = training.df,
              method = &quot;ada&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = adaGrid,
              loss = &quot;exponential&quot;,
              type = &quot;discrete&quot;
              )

print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)

FNR(pred.y, test.y)
FPR(pred.y, test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;ADABOOST&#39;</code></pre>
</div>
<div id="svm-models" class="section level1" number="5">
<h1><span class="header-section-number">5</span> SVM models</h1>
<div id="svmlinearweights-linear-kernel-class-weights" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> svmLinearWeights (linear kernel + class weights)</h2>
<pre class="r"><code>modelLookup(&quot;svmLinearWeights&quot;)
             model parameter        label forReg forClass probModel
1 svmLinearWeights      cost         Cost  FALSE     TRUE      TRUE
2 svmLinearWeights    weight Class Weight  FALSE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(50)
# Customzing the tuning grid
svmgrid &lt;-  expand.grid(cost = c(0.01,0.015, 0.02),
                        weight = c(0.45) 
                        )



# training a svm classifier with liearn kernel model while tuning parameters
model = caret::train(Tumor~., data = training.df,
              method = &quot;svmLinearWeights&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = svmgrid)

# summarizing the results
#print(model)</code></pre>
<pre class="r"><code>plot(model)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-20-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.7456</code></pre>
<pre class="r"><code>
FNR(pred.y, test.y)
     class.pred
truth  0  1
    0  2  4
    1  2 17
[1] 0.1052632</code></pre>
<pre class="r"><code>FPR(pred.y, test.y)
     class.pred
truth  0  1
    0  2  4
    1  2 17
[1] 0.6666667</code></pre>
<pre class="r"><code>
roc_svmlinear_cn &lt;- ROCit::rocit(score=pred.y,class=test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;SVMLinear&#39;</code></pre>
</div>
<div id="svmradial-support-vector-machines-with-radial-basis-function-kernel" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> svmRadial (Support Vector Machines with Radial Basis Function Kernel)</h2>
<pre class="r"><code>modelLookup(&quot;svmRadial&quot;)
      model parameter label forReg forClass probModel
1 svmRadial     sigma Sigma   TRUE     TRUE      TRUE
2 svmRadial         C  Cost   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(50)
svmgrid &lt;-  expand.grid(sigma=c(0.01, 0.05,0.5,1,3, 5, 10), C = c(0.01, 0.05,0.5,1,3,5,10))

# training a svm with rbf kernel classifier model while tuning parameters
model = caret::train(Tumor~., data = training.df,
              method = &quot;svmRadial&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = svmgrid)

# summarizing the results
#print(model)</code></pre>
<pre class="r"><code>plot(model)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-25-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.7895</code></pre>
<pre class="r"><code>
FNR(pred.y, test.y)
     class.pred
truth  0  1
    0  2  4
    1  3 16
[1] 0.1578947</code></pre>
<pre class="r"><code>FPR(pred.y, test.y)
     class.pred
truth  0  1
    0  2  4
    1  3 16
[1] 0.6666667</code></pre>
<pre class="r"><code>
roc_svmradial_cn &lt;- ROCit::rocit(score=pred.y,class=test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;SVMRadial&#39;</code></pre>
</div>
<div id="svmpoly-support-vector-machines-with-polynomial-kernel" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> svmPoly (Support Vector Machines with Polynomial Kernel)</h2>
<pre class="r"><code>modelLookup(&quot;svmPoly&quot;)
    model parameter             label forReg forClass probModel
1 svmPoly    degree Polynomial Degree   TRUE     TRUE      TRUE
2 svmPoly     scale             Scale   TRUE     TRUE      TRUE
3 svmPoly         C              Cost   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(111)
svmgrid &lt;-  expand.grid(degree = c(2,3,4,5),
                        scale = c(0.001,0.01,0.5,1),
                        C = c(0.1,0.5,1,5,10, 100)
                        )

# training a svm with poly kernel classifier tree model while tuning parameters
model = caret::train(Tumor~., data = training.df,
              method = &quot;svmPoly&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = svmgrid)

#print(model)</code></pre>
<pre class="r"><code>plot(model)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-30-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.7281</code></pre>
<pre class="r"><code>
FNR(pred.y, test.y)
     class.pred
truth  0  1
    0  1  5
    1  4 15
[1] 0.2105263</code></pre>
<pre class="r"><code>FPR(pred.y, test.y)
     class.pred
truth  0  1
    0  1  5
    1  4 15
[1] 0.8333333</code></pre>
<pre class="r"><code>
roc_svmpoly_cn &lt;- ROCit::rocit(score=pred.y,class=test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;SVMPoly&#39;</code></pre>
</div>
</div>
<div id="random-forest" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Random forest</h1>
<pre class="r"><code>modelLookup(&quot;rf&quot;)
  model parameter                         label forReg forClass probModel
1    rf      mtry #Randomly Selected Predictors   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(111)
rfgrid &lt;-  expand.grid(mtry = c(1:30) #only parameter you can tune for rf in R
                        )

# training a randomForest classifier tree model while tuning parameters
model = caret::train(Tumor~., data = training.df,
              method = &quot;rf&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              importance = T,
              #manually set
              ntree = 700, #was a good number
              nodesize = 1, #default for classification
              tuneGrid = rfgrid)

#print(model)</code></pre>
<pre class="r"><code>plot(model)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-35-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.7456</code></pre>
<pre class="r"><code>
FNR(pred.y, test.y)
     class.pred
truth  0  1
    0  1  5
    1  2 17
[1] 0.1052632</code></pre>
<pre class="r"><code>FPR(pred.y, test.y)
     class.pred
truth  0  1
    0  1  5
    1  2 17
[1] 0.8333333</code></pre>
<pre class="r"><code>
roc_rf_cn &lt;- ROCit::rocit(score=pred.y,class=test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;RandomForest&#39;</code></pre>
</div>
<div id="elastic-net" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Elastic net</h1>
<pre class="r"><code>modelLookup(&quot;glmnet&quot;)
   model parameter                    label forReg forClass probModel
1 glmnet     alpha        Mixing Percentage   TRUE     TRUE      TRUE
2 glmnet    lambda Regularization Parameter   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(111)
netgrid &lt;-  expand.grid(alpha = c(0.1, 0.2, 0.5, 0.7, 0.9), 
                        lambda = c(0,0.05,0.1, 0.2, 0.25, 0.3, 0.35, 0.4, 1, 5, 10) 
                        )


# training a elastic net classifier tree model while tuning parameters
model = caret::train(Tumor~., data = training.df,
              method = &quot;glmnet&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = netgrid)

# summarizing the results
#print(model)</code></pre>
<pre class="r"><code>plot(model)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-41-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#predict on test data
pred.y &lt;- predict(model, testing.df, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test.y &lt;- as.numeric(testing.df[, 1]) -1

pROC::auc(test.y, pred.y)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.693</code></pre>
<pre class="r"><code>
FNR(pred.y, test.y)
     class.pred
truth  0  1
    0  2  4
    1  5 14
[1] 0.2631579</code></pre>
<pre class="r"><code>FPR(pred.y, test.y)
     class.pred
truth  0  1
    0  2  4
    1  5 14
[1] 0.6666667</code></pre>
<pre class="r"><code>
roc_elastic_cn &lt;- ROCit::rocit(score=pred.y,class=test.y)</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(test.y, pred.y), FNR(pred.y, test.y), FPR(pred.y, test.y)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;ElasticNet&#39;</code></pre>
</div>
<div id="keras-nn" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Keras NN</h1>
<pre class="r"><code>library(tensorflow)

Attaching package: &#39;tensorflow&#39;
The following object is masked from &#39;package:caret&#39;:

    train</code></pre>
<pre class="r"><code>library(keras)

Attaching package: &#39;keras&#39;
The following object is masked from &#39;package:BiocGenerics&#39;:

    normalize</code></pre>
<pre class="r"><code>library(tfruns)
tensorflow::set_random_seed(111)</code></pre>
<p>Use gene names now. ADAboost was having a bug with with these names so this step was moved to this part.</p>
<p>Training data</p>
<pre class="r"><code>training.df &lt;- data.frame(Tumor = seR.intercept$Tumor,
                          scale(t(assays(seR.intercept)$logCPM), scale = TRUE, center = TRUE))
len &lt;- length(training.df)
colnames(training.df)[2:len] &lt;- rowData(seR.intercept)[[&quot;Symbol&quot;]]</code></pre>
<p>Testing data</p>
<pre class="r"><code>testing.df &lt;- data.frame(Tumor = seB.intercept$Tumor,
                          scale(t(assays(seB.intercept)$logCPM), scale = TRUE, center = TRUE))
len &lt;- length(testing.df)
colnames(testing.df)[2:len]  &lt;- rowData(seB.intercept)[[&quot;Symbol&quot;]]</code></pre>
<pre class="r"><code>x_train &lt;- as.matrix(training.df[,-1])
y_train &lt;- as.matrix(as.numeric(training.df[,1])-1)

x_test&lt;- as.matrix(testing.df[,-1])
y_test &lt;- as.matrix(as.numeric(testing.df[,1])-1)

x_train_shape &lt;- length(colnames(x_train))</code></pre>
<pre class="r"><code>model &lt;- keras_model_sequential()
model %&gt;%
  layer_dense(units = 1500, activation = &#39;relu&#39;,
              input_shape = c(x_train_shape),
              kernel_regularizer = regularizer_l1_l2(l1 = 0.00000001, l2 = 0.00001),
              bias_regularizer = regularizer_l1_l2(l1 = 0.00001, l2 = 0.0001),
              kernel_constraint =constraint_maxnorm(max_value = 2, axis = 0),
              #bias_constraint =constraint_maxnorm(max_value = 3, axis = 0),
              activity_regularizer= regularizer_l1_l2(l1 = 0.01, l2 = 0.00001),
              ) %&gt;%  
  layer_dropout(rate = 0.5) %&gt;% 
  layer_batch_normalization() %&gt;%
  layer_dense(units = 500, activation = &#39;relu&#39;,
              kernel_regularizer = regularizer_l1_l2(l1 = 0.1, l2 = 0.1),
              kernel_constraint = constraint_minmaxnorm(max_value = 2, min_value = 0, axis = 1),
              bias_regularizer = regularizer_l1_l2(l1 = 0.00001, l2 = 0.000001),
              #bias_constraint =constraint_maxnorm(max_value = 3, axis = 0),
              activity_regularizer = regularizer_l1_l2(l1 = 0.1, l2 = 0.000001),
              ) %&gt;%
  layer_dropout(rate = 0.3) %&gt;%
  layer_batch_normalization() %&gt;%
  layer_dense(units = 1, activation = &#39;sigmoid&#39;)</code></pre>
<pre class="r"><code>loss_fn &lt;- loss_binary_crossentropy()
auc &lt;- metric_auc()
adam &lt;- optimizer_adam(learning_rate = 0.0001, ema_momentum = 0.99)

model %&gt;% compile(
  optimizer = adam,
  loss = loss_fn,
  metrics = &quot;AUC&quot;
)</code></pre>
<pre class="r"><code>model %&gt;% fit(x_train, y_train, epochs = 150, batch_size =5)</code></pre>
<pre class="r"><code>model %&gt;% evaluate(x_test,  y_test, verbose = 2)
1/1 - 0s - loss: 4.5354 - auc: 0.9737 - 146ms/epoch - 146ms/step
     loss       auc 
4.5353580 0.9736842 </code></pre>
<pre class="r"><code>b&lt;-model %&gt;% predict(x_test) #%&gt;% `&gt;`(0.5) %&gt;% k_cast(&quot;int32&quot;) 
1/1 - 0s - 64ms/epoch - 64ms/step</code></pre>
<pre class="r"><code>b &lt;- as.numeric(b)
b
 [1] 0.6603139 0.1790317 0.6191009 0.7149007 0.6164845 0.9392020 0.2831569
 [8] 0.2224904 0.8566977 0.4016270 0.8135931 0.8040830 0.7177238 0.5698699
[15] 0.2889983 0.1429354 0.6454641 0.3611163 0.6688172 0.5154021 0.6794097
[22] 0.6509840 0.6441412 0.6635723 0.8521053</code></pre>
<pre class="r"><code>pROC::auc(as.numeric(y_test), b)
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases
Area under the curve: 0.9737</code></pre>
<pre class="r"><code>
FNR(b, y_test)
     class.pred
truth  0  1
    0  5  1
    1  0 19
[1] 0</code></pre>
<pre class="r"><code>FPR(b, y_test)
     class.pred
truth  0  1
    0  5  1
    1  0 19
[1] 0.1666667</code></pre>
<pre class="r"><code>
roc_nnet_cn &lt;- ROCit::rocit(score=b,class=as.numeric(y_test))</code></pre>
<pre class="r"><code># Add to output
res.testing &lt;- rbind.data.frame(res.testing, c(pROC::auc(y_test, b), FNR(b, y_test), FPR(b, y_test)))
Setting levels: control = 0, case = 1
Warning in roc.default(response, predictor, auc = TRUE, ...): Deprecated use a
matrix as response. Unexpected results may be produced, please pass a vector or
factor.
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing)[nrow(res.testing)] &lt;- &#39;Nnet&#39;</code></pre>
</div>
<div id="roc-auc-curve-for-all-models" class="section level1" number="9">
<h1><span class="header-section-number">9</span> ROC-AUC curve for all models</h1>
<pre class="r"><code>plot(roc_xgboost_cn$TPR ~ roc_xgboost_cn$FPR, type = &quot;n&quot;, 
 xlab = &quot;1 - Specificity (FPR)&quot;, ylab = &quot;Sensitivity (TPR)&quot;)
abline(0, 1, col = &quot;gray&quot;, lty = 2, lwd = 2)

lines(roc_nnet_cn$TPR ~ roc_nnet_cn$FPR, col = 7, lwd = 2, lty = 1)  
lines(roc_svmradial_cn$TPR ~ roc_svmradial_cn$FPR, col = 3, lwd = 2, lty = 1)  
lines(roc_svmlinear_cn$TPR ~ roc_svmlinear_cn$FPR, col = 2, lwd = 2, lty = 1)
lines(roc_rf_cn$TPR ~ roc_rf_cn$FPR, col = 5, lwd = 2, lty = 1)
lines(roc_svmpoly_cn$TPR ~ roc_svmpoly_cn$FPR, col = 4, lwd = 2, lty = 1)
lines(roc_elastic_cn$TPR ~ roc_elastic_cn$FPR, col = 6, lwd = 2, lty = 1)
lines(roc_xgboost_cn$TPR -0.05 ~ roc_xgboost_cn$FPR, col = 1, lwd = 2, lty = 1)  


legend(&quot;bottomright&quot;, col = c(1,2,3,4,5,6,7),
       legend = c(paste(&quot;XGboost&quot;,&quot;AUC:&quot;,round(roc_xgboost_cn$AUC,2)),
                  paste(&quot;SVM linear&quot;,&quot;AUC:&quot;,round(roc_svmlinear_cn$AUC,2)),
                  paste(&quot;SVM rbf&quot;,&quot;AUC:&quot;,round(roc_svmradial_cn$AUC,2)),
                  paste(&quot;SVM poly&quot;,&quot;AUC:&quot;,round(roc_svmpoly_cn$AUC,2)),
                  paste(&quot;Random forest&quot;,&quot;AUC:&quot;,round(roc_rf_cn$AUC,2)),
                  paste(&quot;Elastic net&quot;,&quot;AUC:&quot;,round(roc_elastic_cn$AUC,2)),
                  paste(&quot;Neural network&quot;,&quot;AUC:&quot;,round(roc_nnet_cn$AUC,2))), 
       lwd = 2, lty = 1,
       cex = 0.8, 
       pt.cex = 0.8, 
       x.intersp = 1, y.intersp = 1)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-56-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
</div>
<div id="model-perfomancesresults-in-table" class="section level1" number="10">
<h1><span class="header-section-number">10</span> Model perfomances/results in table</h1>
<pre class="r"><code>(res.testing)
                   AUC       FNR       FPR
XGBOOST      0.7368421 0.3684211 0.1666667
ADABOOST     0.7368421 0.3684211 0.1666667
SVMLinear    0.7456140 0.1052632 0.6666667
SVMRadial    0.7894737 0.1578947 0.6666667
SVMPoly      0.7280702 0.2105263 0.8333333
RandomForest 0.7456140 0.1052632 0.8333333
ElasticNet   0.6929825 0.2631579 0.6666667
Nnet         0.9736842 0.0000000 0.1666667</code></pre>
</div>
<div id="shap-value-global-explanation-logistic-regression-with-most-important-genes" class="section level1" number="11">
<h1><span class="header-section-number">11</span> SHAP value (Global explanation) + logistic regression with most important genes</h1>
<p>Extract feature importance values for each gene. Model considered is neural network.</p>
<pre class="r"><code>library(kernelshap)
library(shapviz)
library(ggplot2)
library(patchwork)
X &lt;- x_test 
s &lt;- shapviz(kernelshap(model, X, bg_X = x_train))
1/1 - 0s - 12ms/epoch - 12ms/step
2/2 - 0s - 13ms/epoch - 7ms/step
Kernel SHAP values by the hybrid strategy of degree 1

  |                                                                            
  |                                                                      |   0%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |===                                                                   |   4%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |======                                                                |   8%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |========                                                              |  12%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |===========                                                           |  16%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |==============                                                        |  20%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |=================                                                     |  24%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |====================                                                  |  28%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |======================                                                |  32%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |=========================                                             |  36%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 4s - 4s/epoch - 2ms/step

  |                                                                            
  |============================                                          |  40%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |===============================                                       |  44%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |==================================                                    |  48%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |====================================                                  |  52%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |=======================================                               |  56%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |==========================================                            |  60%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |=============================================                         |  64%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |================================================                      |  68%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |==================================================                    |  72%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |=====================================================                 |  76%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |========================================================              |  80%2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |===========================================================           |  84%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |==============================================================        |  88%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step

  |                                                                            
  |================================================================      |  92%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |===================================================================   |  96%2034/2034 - 3s - 3s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step
2034/2034 - 2s - 2s/epoch - 1ms/step

  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>sv_importance(s, kind = &quot;bee&quot;, show_numbers = TRUE) + theme_classic()</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-62-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#sv_dependence(s, colnames(X), color_var = NULL) &amp;
#  ylim(-4, 4)
sv_importance(s, max_display=30)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-62-2.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<pre class="r"><code>sv_waterfall(s, row_id = 3)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-62-3.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<p>Distribution of shapley values obtained from our model.</p>
<pre class="r"><code>shap.value.list&lt;- colMeans(abs(s$S))
ordered.shap.value.list &lt;- shap.value.list[order(-abs(shap.value.list))]
histogram(ordered.shap.value.list, breaks = 50)</code></pre>
<p><img src="06_pr_cn_files/figure-html/unnamed-chunk-64-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<p>Logistic regression with top 3 most important genes by SHAP.</p>
<pre class="r"><code>shap.cutoff &lt;- 3

new.train &lt;- training.df[,c(&quot;Tumor&quot;,names(ordered.shap.value.list)[1:shap.cutoff])]
new.test &lt;- testing.df[,c(&quot;Tumor&quot;,names(ordered.shap.value.list)[1:shap.cutoff])]

logistic.shap &lt;- glm(Tumor ~., family = &quot;binomial&quot;, data = new.train)

summary(logistic.shap)

Call:
glm(formula = Tumor ~ ., family = &quot;binomial&quot;, data = new.train)

Coefficients:
            Estimate Std. Error z value Pr(&gt;|z|)   
(Intercept) -0.01305    0.35996  -0.036  0.97108   
CTSW         0.78221    0.48859   1.601  0.10939   
CD96         1.49858    0.57762   2.594  0.00948 **
AIF1L        1.39691    0.50626   2.759  0.00579 **
---
Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 80.336  on 57  degrees of freedom
Residual deviance: 50.019  on 54  degrees of freedom
AIC: 58.019

Number of Fisher Scoring iterations: 5</code></pre>
<pre class="r"><code>predicted.proba.logistic.shap.test &lt;- predict(logistic.shap, new.test[-1], type=&quot;response&quot;)
pROC::auc(new.test[,1], predicted.proba.logistic.shap.test)
Setting levels: control = no, case = yes
Setting direction: controls &lt; cases
Area under the curve: 0.7632</code></pre>
<pre class="r"><code>
FNR(predicted.proba.logistic.shap.test, new.test[,1])
     class.pred
truth  0  1
  no   5  1
  yes  6 13
[1] 0.3157895</code></pre>
<pre class="r"><code>FPR(predicted.proba.logistic.shap.test, new.test[,1])
     class.pred
truth  0  1
  no   5  1
  yes  6 13
[1] 0.1666667</code></pre>
<p>Trial with 3 first genes without ordering by SHAP</p>
<pre class="r"><code>trial.train &lt;- training.df[,1:shap.cutoff]
trial.test &lt;- testing.df[,1:shap.cutoff]

logistic.shap &lt;- glm(Tumor ~., family = &quot;binomial&quot;, data = trial.train)

predicted.proba.logistic.shap.test &lt;- predict(logistic.shap, trial.test[-1], type=&quot;response&quot;)
pROC::auc(trial.test[,1], predicted.proba.logistic.shap.test)
Setting levels: control = no, case = yes
Setting direction: controls &lt; cases
Area under the curve: 0.5088</code></pre>
<pre class="r"><code>
FNR(predicted.proba.logistic.shap.test, trial.test[,1])
     class.pred
truth  0  1
  no   0  6
  yes  8 11
[1] 0.4210526</code></pre>
<pre class="r"><code>FPR(predicted.proba.logistic.shap.test, trial.test[,1])
     class.pred
truth  0  1
  no   0  6
  yes  8 11
[1] 1</code></pre>
</div>
<div id="session-information" class="section level1" number="12">
<h1><span class="header-section-number">12</span> Session information</h1>
<pre class="r"><code>sessionInfo()
R version 4.4.0 (2024-04-24)
Platform: x86_64-pc-linux-gnu
Running under: Ubuntu 22.04.4 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=es_ES.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C       

time zone: Europe/Madrid
tzcode source: system (glibc)

attached base packages:
[1] stats4    stats     graphics  grDevices utils     datasets  methods  
[8] base     

other attached packages:
 [1] patchwork_1.2.0             shapviz_0.9.3              
 [3] kernelshap_0.5.0            tfruns_1.5.3               
 [5] keras_2.15.0                tensorflow_2.16.0.9000     
 [7] edgeR_4.2.0                 limma_3.60.2               
 [9] SummarizedExperiment_1.34.0 Biobase_2.64.0             
[11] GenomicRanges_1.56.0        GenomeInfoDb_1.40.1        
[13] IRanges_2.38.0              S4Vectors_0.42.0           
[15] BiocGenerics_0.50.0         MatrixGenerics_1.16.0      
[17] matrixStats_1.3.0           randomForest_4.7-1.1       
[19] xgboost_1.7.7.1             ROCit_2.1.2                
[21] caret_6.0-94                lattice_0.22-5             
[23] ggplot2_3.5.1               dplyr_1.1.4                
[25] lime_0.5.3                  glmnet_4.1-8               
[27] Matrix_1.6-5                kableExtra_1.4.0           
[29] knitr_1.46                  BiocStyle_2.32.0           

loaded via a namespace (and not attached):
  [1] rstudioapi_0.16.0       jsonlite_1.8.8          shape_1.4.6            
  [4] magrittr_2.0.3          farver_2.1.1            rmarkdown_2.27         
  [7] zlibbioc_1.50.0         vctrs_0.6.5             shades_1.4.0           
 [10] base64enc_0.1-3         tinytex_0.49            htmltools_0.5.8.1      
 [13] S4Arrays_1.4.1          SparseArray_1.4.8       pROC_1.18.5            
 [16] sass_0.4.9              parallelly_1.36.0       bslib_0.7.0            
 [19] plyr_1.8.9              lubridate_1.9.3         cachem_1.0.8           
 [22] ggfittext_0.10.2        whisker_0.4.1           lifecycle_1.0.4        
 [25] iterators_1.0.14        pkgconfig_2.0.3         R6_2.5.1               
 [28] fastmap_1.2.0           GenomeInfoDbData_1.2.12 future_1.33.1          
 [31] digest_0.6.35           colorspace_2.1-0        rprojroot_2.0.4        
 [34] labeling_0.4.3          fansi_1.0.6             timechange_0.3.0       
 [37] httr_1.4.7              abind_1.4-5             compiler_4.4.0         
 [40] here_1.0.1              proxy_0.4-27            withr_3.0.0            
 [43] highr_0.9               MASS_7.3-60.0.1         lava_1.7.3             
 [46] rappdirs_0.3.3          DelayedArray_0.30.1     ModelMetrics_1.2.2.2   
 [49] tools_4.4.0             future.apply_1.11.1     nnet_7.3-19            
 [52] glue_1.7.0              nlme_3.1-163            grid_4.4.0             
 [55] reshape2_1.4.4          gggenes_0.5.1           generics_0.1.3         
 [58] recipes_1.0.10          gtable_0.3.4            class_7.3-22           
 [61] data.table_1.15.0       xml2_1.3.6              utf8_1.2.4             
 [64] XVector_0.44.0          foreach_1.5.2           pillar_1.9.0           
 [67] stringr_1.5.1           splines_4.4.0           survival_3.5-8         
 [70] tidyselect_1.2.1        locfit_1.5-9.9          bookdown_0.39          
 [73] svglite_2.1.3           xfun_0.44               statmod_1.4.37         
 [76] hardhat_1.3.1           timeDate_4032.109       stringi_1.8.3          
 [79] UCSC.utils_1.0.0        yaml_2.3.8              evaluate_0.23          
 [82] codetools_0.2-19        kernlab_0.9-32          tibble_3.2.1           
 [85] BiocManager_1.30.23     cli_3.6.2               rpart_4.1.23           
 [88] reticulate_1.37.0       systemfonts_1.0.5       munsell_0.5.0          
 [91] jquerylib_0.1.4         Rcpp_1.0.12             globals_0.16.2         
 [94] zeallot_0.1.0           png_0.1-8               parallel_4.4.0         
 [97] gower_1.0.0             assertthat_0.2.1        listenv_0.9.1          
[100] viridisLite_0.4.2       ipred_0.9-14            scales_1.3.0           
[103] prodlim_2023.08.28      e1071_1.7-14            purrr_1.0.2            
[106] crayon_1.5.2            rlang_1.1.3            </code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Block2022" class="csl-entry">
Block, Timothy, Daniel Zezulinski, David Kaplan, Jingqiao Lu, Samantha Zanine, Tingting Zhan, Cataldo Doria, and Aejaz Sayeed. 2022. <span>‚ÄúCirculating Messenger RNA Variants as a Potential Biomarker for Surveillance of Hepatocellular Carcinoma.‚Äù</span> <em>Frontiers in Oncology</em> 12. <a href="https://doi.org/10.3389/fonc.2022.963641">https://doi.org/10.3389/fonc.2022.963641</a>.
</div>
<div id="ref-Roskams2022" class="csl-entry">
Roskams-Hieter, Breeshey, Hyun Ji Kim, Pavana Anur, Josiah T. Wagner, Rowan Callahan, Elias Spiliotopoulos, Charles Ward Kirschbaum, et al. 2022. <span>‚ÄúPlasma Cell-Free RNA Profiling Distinguishes Cancers from Pre-Malignant Conditions in Solid and Hematologic Malignancies.‚Äù</span> <em>Npj Precision Oncology</em> 6. <a href="https://doi.org/10.1038/s41698-022-00270-y">https://doi.org/10.1038/s41698-022-00270-y</a>.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
      styles: {
        ".MathJax_Display": {
           "text-align": "center",
           padding: "0px 150px 0px 65px",
           margin: "0px 0px 0.5em"
        },
        "@media screen and (max-width: 991px)": {
            ".MathJax_Display": {
               "text-align": "center",
               padding: "0 0 0 0"
            }
         }
      }
    }
  });
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<script type="text/javascript">
$(document).ready(function ()  {
  
  // Map "enter" keypress to the same action as a cursor click
  function navigateLink(e) {
    if (e.key === "Enter") {
      $(this).trigger("click");
    }
  }

  var toc_items = document.querySelectorAll(".tocify-item");
  for (var i = 0; i < toc_items.length; i++) {
    // The link role tells screen readers this is for navigation
    toc_items.item(i).setAttribute("role", "link");
    // tabindex = 0 allows selection via keyboard tab presses
    toc_items.item(i).setAttribute("tabindex", "0");
    // Listen for "Enter" keypress when item is selected
    toc_items.item(i).addEventListener("keydown", navigateLink);
  }
});
</script>

</body>
</html>
