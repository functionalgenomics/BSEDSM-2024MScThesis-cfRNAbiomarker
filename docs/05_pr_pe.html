<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Biomarker prediction in preeclampsia data</title>

<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       </style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>


<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="/home/adam/R/x86_64-pc-linux-gnu-library/4.4/BiocStyle/resources/html/bioconductor.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 828px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {

}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 246px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



<script>
function toggle_visibility(id1) {
  var e = document.getElementById(id1);
  e.style.display = ((e.style.display!="none") ? "none" : "block");
}
</script>

</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Biomarker Discovery in cfRNA data</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="01_qa_pe.html">QA Preeclampsia</a>
</li>
<li>
  <a href="02_de_pe.html">DE Preeclampsia</a>
</li>
<li>
  <a href="03_qa_cn.html">QA Cancer</a>
</li>
<li>
  <a href="04_de_cn.html">DE Cancer</a>
</li>
<li>
  <a href="05_pr_pe.html">Prediction preeclampsia</a>
</li>
<li>
  <a href="06_pr_cn.html">Prediction cancer</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Biomarker prediction in preeclampsia data</h1>
<p class="author-name">Berta Canal Sim√≥n<span class="affil-mark">1*</span> and Adam Olivares Canal<span class="affil-mark">1**</span></p>
<p class="author-affiliation"><span class="affil-mark">1</span>Barcelona School of Economics</p>
<p class="author-email"><span class="affil-mark">*</span><a href="mailto:berta.canal@bse.eu">berta.canal@bse.eu</a><br><span class="affil-mark">**</span><a href="mailto:adam.olivares@bse.eu">adam.olivares@bse.eu</a></p>
<h4 class="date">junio 8, 2024</h4>
<h4 class="abstract">Abstract</h4>
<p>Here we perform a prediction of candidate biomarkers in preeclampsia cfRNA sequencing data.</p>

</div>


<pre><code>## Loading required package: ggplot2</code></pre>
<pre><code>## Loading required package: lattice</code></pre>
<div id="importing-processed-and-filtered-data" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Importing processed and filtered data</h1>
<p>We start by importing the previously filtered and normalized RNA-seq data.</p>
<pre class="r"><code>library(SummarizedExperiment)
library(edgeR)

dgeM.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;dgeM.filt.rds&quot;))
seM.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;seM.filt.rds&quot;))
dgeD.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;dgeD.filt.rds&quot;))
seD.filt &lt;- readRDS(file.path(&quot;_processed_data&quot;, &quot;seD.filt.rds&quot;))
dgeM.filt.training &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                        &quot;dgeM.filt.training.rds&quot;))
seM.filt.training &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                       &quot;seM.filt.training.rds&quot;))
dgeM.filt.testing &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                       &quot;dgeM.filt.testing.rds&quot;))
seM.filt.testing &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                      &quot;seM.filt.testing.rds&quot;))
dgeD.filt.subset &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                      &quot;dgeD.filt.subset.rds&quot;))
seD.filt.subset &lt;- readRDS(file.path(&quot;_processed_data&quot;,
                                     &quot;seD.filt.subset.rds&quot;))
DEgenes.trainingM &lt;- readRDS(file.path(&quot;_processed_data&quot;, 
                                      &quot;DEgenes.trainingM.rds&quot;))
DEgenes.testingM &lt;- readRDS(file.path(&quot;_processed_data&quot;, 
                                      &quot;DEgenes.testingM.rds&quot;))
DEgenes.testingD &lt;- readRDS(file.path(&quot;_processed_data&quot;, 
                                      &quot;DEgenes.testingD.rds&quot;))</code></pre>
<p>Train-testing subset creation: Intersection between differential expressed genes from training set from <span class="citation">Roskams-Hieter et al. (<a href="#ref-Roskams2022">2022</a>)</span> and lowly expressed genes from testing set.</p>
<pre class="r"><code>set.seed(111)
intersection.genes &lt;- Reduce(intersect, list(DEgenes.trainingM, rownames(dgeM.filt.testing), rownames(dgeD.filt.subset)))
length(intersection.genes)
[1] 912</code></pre>
<pre class="r"><code>
#intersection.genes &lt;- intersect(intersect(DEgenes.trainingM, rownames(dgeM.filt.testing)), rownames(dgeD.filt.subset))
#length(intersection.genes)

dgeM.intercept.training &lt;- dgeM.filt.training[intersection.genes,]
dim(dgeM.intercept.training)
[1] 912 244</code></pre>
<pre class="r"><code>seM.intercept.training &lt;- seM.filt.training[intersection.genes,]
dim(seM.intercept.training)
[1] 912 244</code></pre>
<pre class="r"><code>
dgeM.intercept.testing &lt;- dgeM.filt.testing[intersection.genes,]
dim(dgeM.intercept.testing)
[1] 912  89</code></pre>
<pre class="r"><code>seM.intercept.testing &lt;- seM.filt.testing[intersection.genes,]
dim(seM.intercept.testing)
[1] 912  89</code></pre>
<pre class="r"><code>
dgeD.intercept.testing &lt;- dgeD.filt.subset[intersection.genes,]
dim(dgeD.intercept.testing)
[1] 912  76</code></pre>
<pre class="r"><code>seD.intercept.testing &lt;- seD.filt.subset[intersection.genes,]
dim(seD.intercept.testing)
[1] 912  76</code></pre>
<div id="pregnancy-trimesters" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Pregnancy trimesters</h2>
<p>Gestational age is used to classify the samples into its corresponding trimester of pregnancy according to <a href="https://www.nichd.nih.gov/health/topics/factsheets/pregnancy">NIH</a>: first trimester (week 1 to week 12), second trimester (week 13 to week 28) and third trimester (week 29 to week 40).</p>
<div id="training-data" class="section level3" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Training data</h3>
<pre class="r"><code>table(as.factor(seM.intercept.training$SamplingGAgroup))

  ‚â§12 weeks gestation   ‚â•23 weeks gestation 13-20 weeks gestation 
                   72                    84                    88 </code></pre>
<pre class="r"><code>mask &lt;- seM.intercept.training$SamplingGA &lt;= 16
seM.intercept.training$SamplingGAgroup17[mask] &lt;- &quot;Pre17weeks&quot;
dgeM.intercept.training$samples$SamplingGAgroup17[mask] &lt;- &quot;Pre17weeks&quot;

mask &lt;- seM.intercept.training$SamplingGA &gt;= 17
seM.intercept.training$SamplingGAgroup17[mask] &lt;- &quot;Post17weeks&quot;
dgeM.intercept.training$samples$SamplingGAgroup17[mask] &lt;- &quot;Post17weeks&quot;</code></pre>
<pre class="r"><code>table(as.factor(seM.intercept.training$SamplingGAgroup17))

Post17weeks  Pre17weeks 
        116         128 </code></pre>
</div>
<div id="testing-data-1" class="section level3" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Testing data 1</h3>
<pre class="r"><code>table(as.factor(seM.intercept.testing$SamplingGAgroup))

  ‚â§12 weeks gestation 13-20 weeks gestation 
                   56                    33 </code></pre>
<pre class="r"><code>mask &lt;- seM.intercept.testing$SamplingGA &lt;= 16
seM.intercept.testing$SamplingGAgroup17[mask] &lt;- &quot;Pre17weeks&quot;
dgeM.intercept.testing$samples$SamplingGAgroup17[mask] &lt;- &quot;Pre17weeks&quot;

mask &lt;- seM.intercept.testing$SamplingGA &gt;= 17
seM.intercept.testing$SamplingGAgroup17[mask] &lt;- &quot;Post17weeks&quot;
dgeM.intercept.testing$samples$SamplingGAgroup17[mask] &lt;- &quot;Post17weeks&quot;</code></pre>
<pre class="r"><code>table(as.factor(seM.intercept.testing$SamplingGAgroup17))

Pre17weeks 
        89 </code></pre>
</div>
<div id="testing-data-2" class="section level3" number="1.1.3">
<h3><span class="header-section-number">1.1.3</span> Testing data 2</h3>
<pre class="r"><code>table(as.factor(seD.intercept.testing$SamplingGAgroup))

1st Trimester 2nd Trimester 3rd Trimester 
           25            26            25 </code></pre>
<pre class="r"><code>mask &lt;- seD.intercept.testing$SamplingGA &lt;= 16
seD.intercept.testing$SamplingGAgroup17[mask] &lt;- &quot;Pre17weeks&quot;
dgeD.intercept.testing$samples$SamplingGAgroup17[mask] &lt;- &quot;Pre17weeks&quot;

mask &lt;- seD.intercept.testing$SamplingGA &gt;= 17
seD.intercept.testing$SamplingGAgroup17[mask] &lt;- &quot;Post17weeks&quot;
dgeD.intercept.testing$samples$SamplingGAgroup17[mask] &lt;- &quot;Post17weeks&quot;</code></pre>
<pre class="r"><code>table(as.factor(seD.intercept.testing$SamplingGAgroup17))

Post17weeks  Pre17weeks 
         55          21 </code></pre>
</div>
</div>
<div id="dataframes-creation" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Dataframes creation</h2>
<div id="training-data-1" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Training data</h3>
<pre class="r"><code>training.df &lt;- data.frame(Preeclampsia = seM.intercept.training$Preeclampsia,
                          SamplingGA = scale(seM.intercept.training$SamplingGA, scale = TRUE, center = TRUE),
                          SamplingGAgroup17 = seM.intercept.training$SamplingGAgroup17,
                          scale(t(assays(seM.intercept.training)$logCPM), scale = TRUE, center = TRUE),
                          MotherID = seM.intercept.training$MotherID
                          )</code></pre>
<pre class="r"><code>mask &lt;- seM.intercept.training$SamplingGAgroup17 == &quot;Pre17weeks&quot;
pre17.training.df &lt;- training.df[mask,]</code></pre>
<pre class="r"><code>library(dplyr)

Attaching package: &#39;dplyr&#39;
The following object is masked from &#39;package:Biobase&#39;:

    combine
The following objects are masked from &#39;package:GenomicRanges&#39;:

    intersect, setdiff, union
The following object is masked from &#39;package:GenomeInfoDb&#39;:

    intersect
The following objects are masked from &#39;package:IRanges&#39;:

    collapse, desc, intersect, setdiff, slice, union
The following objects are masked from &#39;package:S4Vectors&#39;:

    first, intersect, rename, setdiff, setequal, union
The following objects are masked from &#39;package:BiocGenerics&#39;:

    combine, intersect, setdiff, union
The following object is masked from &#39;package:matrixStats&#39;:

    count
The following object is masked from &#39;package:kableExtra&#39;:

    group_rows
The following objects are masked from &#39;package:stats&#39;:

    filter, lag
The following objects are masked from &#39;package:base&#39;:

    intersect, setdiff, setequal, union</code></pre>
<pre class="r"><code>
pre17.training.df &lt;- pre17.training.df %&gt;%
group_by(MotherID) %&gt;%
slice_min(order_by = SamplingGA) %&gt;%
ungroup() %&gt;%
#select(-MotherID, -SamplingGAgroup17) 
select(-MotherID, -SamplingGAgroup17, -SamplingGA)</code></pre>
</div>
<div id="testing-data-1-1" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Testing data 1</h3>
<p>Created from Discovery and Validation 2 dataset in the study by <span class="citation">Moufarrej et al. (<a href="#ref-moufarrej2022early">2022</a>)</span>.</p>
<pre class="r"><code>testing.df1 &lt;- data.frame(Preeclampsia = seM.intercept.testing$Preeclampsia,
                          SamplingGA = scale(seM.intercept.testing$SamplingGA, scale = TRUE, center = TRUE),
                          SamplingGAgroup17 = seM.intercept.testing$SamplingGAgroup17,
                          scale(t(assays(seM.intercept.testing)$logCPM), scale = TRUE, center = TRUE),
                          MotherID = seM.intercept.testing$MotherID
                          )</code></pre>
<pre class="r"><code>mask &lt;- seM.intercept.testing$SamplingGAgroup17 == &quot;Pre17weeks&quot;
pre17.testing.df1 &lt;- testing.df1[mask,]</code></pre>
<pre class="r"><code>pre17.testing.df1 &lt;- pre17.testing.df1 %&gt;%
group_by(MotherID) %&gt;%
slice_min(order_by = SamplingGA) %&gt;%
ungroup() %&gt;%
select(-MotherID, -SamplingGAgroup17, -SamplingGA)</code></pre>
</div>
<div id="testing-data-2-1" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Testing data 2</h3>
<p>Created from the dataset used in the study by <span class="citation">Del Vecchio et al. (<a href="#ref-delvecchio2021cell">2021</a>)</span>.</p>
<pre class="r"><code>testing.df2 &lt;- data.frame(Preeclampsia = seD.intercept.testing$Preeclampsia,
                          SamplingGA = scale(seD.intercept.testing$SamplingGA, scale = TRUE, center = TRUE),
                          SamplingGAgroup17 = seD.intercept.testing$SamplingGAgroup17,
                          scale(t(assays(seD.intercept.testing)$logCPM), scale = TRUE, center = TRUE),
                          MotherID = seD.intercept.testing$MotherID
                          )</code></pre>
<pre class="r"><code>mask &lt;- seD.intercept.testing$SamplingGAgroup17 == &quot;Pre17weeks&quot;
pre17.testing.df2 &lt;- testing.df2[mask,]</code></pre>
<pre class="r"><code>pre17.testing.df2 &lt;- pre17.testing.df2 %&gt;%
group_by(MotherID) %&gt;%
slice_min(order_by = SamplingGA) %&gt;%
ungroup() %&gt;%
select(-MotherID, -SamplingGAgroup17, -SamplingGA)</code></pre>
</div>
</div>
</div>
<div id="performance-metrics" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Performance metrics</h1>
<p>Given the application of the current paper, the False Negative Rate (FNR) metric is a particularly relevant metric, since it would imply classifying as healthy an individual with cancer. Therefore, that patients will not receive treatment, which will cause serious consequences. Furthermore, it could also be considered the False Positive Rate (FPR), which results in an undesirable situation where a proportion of healthy individuals are categorized as ill.¬†This would subject a healthy patient to unnecessary treatment and its potential side effects. However, since the expected consequences are not that severe, FNR is prioritized in the analysis.</p>
<pre class="r"><code>FNR &lt;- function(proba.pred, truth){
  class.pred &lt;- as.numeric(proba.pred &gt; 0.35)
  conf &lt;- table(truth, class.pred)
  print(conf)
  FNR &lt;- conf[2, 1] / sum(conf[2, 1], conf[2, 2])
  return(FNR)
}</code></pre>
<pre class="r"><code>FPR &lt;- function(proba.pred, truth){
  class.pred &lt;- as.numeric(proba.pred &gt; 0.35)
  conf &lt;- table(truth, class.pred)
  print(conf)
  FPR &lt;- conf[1, 2] / sum(conf[1, 1], conf[1, 2])
  return(FPR)
}</code></pre>
</div>
<div id="xgboost" class="section level1" number="3">
<h1><span class="header-section-number">3</span> XGBOOST</h1>
<pre class="r"><code>modelLookup(&quot;xgbTree&quot;)
    model        parameter                          label forReg forClass
1 xgbTree          nrounds          # Boosting Iterations   TRUE     TRUE
2 xgbTree        max_depth                 Max Tree Depth   TRUE     TRUE
3 xgbTree              eta                      Shrinkage   TRUE     TRUE
4 xgbTree            gamma         Minimum Loss Reduction   TRUE     TRUE
5 xgbTree colsample_bytree     Subsample Ratio of Columns   TRUE     TRUE
6 xgbTree min_child_weight Minimum Sum of Instance Weight   TRUE     TRUE
7 xgbTree        subsample           Subsample Percentage   TRUE     TRUE
  probModel
1      TRUE
2      TRUE
3      TRUE
4      TRUE
5      TRUE
6      TRUE
7      TRUE</code></pre>
<pre class="r"><code># CV technique which will be passed into the train() function
train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

# tuning grid
set.seed(111)

#xgboostGrid &lt;- expand.grid(max_depth = c(3, 4, 5, 6, 7), nrounds = (1:20)*10, eta = c(0.4, 0.5),gamma = c(0.5,1, 1.5),subsample = #c(0.8),min_child_weight = c(2),colsample_bytree = c(0.8))

xgboostGrid &lt;- expand.grid(max_depth = c(3, 4, 5, 6, 7), nrounds = (1:20)*10, eta = c(0.2, 0.3, 0.4, 0.5),gamma = c(0.5,1, 1.5),subsample = c(0.8),min_child_weight = c(2),colsample_bytree = c(0.8))

# hyperparaemeter search for XGboost classifier tree model
model = caret::train(Preeclampsia~., data = pre17.training.df,
              method = &quot;xgbTree&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = xgboostGrid,
              verbosity = 0,
              verbose = FALSE,
              #num.threads = 18 #cores in use
              )

#print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred1.y &lt;- predict(model, pre17.testing.df1, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test1.y &lt;- as.numeric(pre17.testing.df1$Preeclampsia)-1

pROC::auc(test1.y, pred1.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.6479</code></pre>
<pre class="r"><code>
FNR(pred1.y, test1.y)
     class.pred
truth  0  1
    0 56  5
    1 19  7
[1] 0.7307692</code></pre>
<pre class="r"><code>FPR(pred1.y, test1.y)
     class.pred
truth  0  1
    0 56  5
    1 19  7
[1] 0.08196721</code></pre>
<pre class="r"><code>
roc_xgboost_pe_test1 &lt;- ROCit::rocit(score=pred1.y,class=test1.y)</code></pre>
<pre class="r"><code># Add to output
res.testing1[1, ] &lt;- c(pROC::auc(test1.y, pred1.y, direction = &quot;&lt;&quot;), FNR(pred1.y, test1.y), FPR(pred1.y, test1.y))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;XGBOOST&#39;</code></pre>
<pre class="r"><code>#predict on test data
pred2.y &lt;- predict(model, pre17.testing.df2, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test2.y &lt;- as.numeric(pre17.testing.df2$Preeclampsia)-1

pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.3365</code></pre>
<pre class="r"><code>
FNR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 8 5
    1 7 1
[1] 0.875</code></pre>
<pre class="r"><code>FPR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 8 5
    1 7 1
[1] 0.3846154</code></pre>
<pre class="r"><code>
roc_xgboost_pe_test2 &lt;- ROCit::rocit(score=pred2.y,class=test2.y)</code></pre>
<pre class="r"><code># Add to output
res.testing2[1, ] &lt;- c(pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;), FNR(pred2.y, test2.y), FPR(pred2.y, test2.y))
Setting levels: control = 0, case = 1
     class.pred
truth 0 1
    0 8 5
    1 7 1
     class.pred
truth 0 1
    0 8 5
    1 7 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;XGBOOST&#39;</code></pre>
</div>
<div id="class-imbalance" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Class imbalance</h1>
<p>Class imbalance is identified since there are 27.5% normotensive and 72.5% preeclampsia pregnancies. Unbalanced problems should be addressed when applying SVM, since it aims to separate the space into two parts.</p>
<pre class="r"><code>#remotes::install_github(&quot;cran/DMwR&quot;)</code></pre>
<pre class="r"><code>smote_dataset &lt;- as.data.frame(pre17.training.df)
smote_dataset$Preeclampsia &lt;- as.factor(smote_dataset$Preeclampsia)
table(pre17.training.df$Preeclampsia)

 no yes 
 66  24 </code></pre>
<pre class="r"><code>#When perc.over is 100, we create 1 new example (100/100 = 1)
library(DMwR)
Loading required package: grid
Registered S3 method overwritten by &#39;quantmod&#39;:
  method            from
  as.zoo.data.frame zoo </code></pre>
<pre class="r"><code>set.seed(111)
resampled.training.df &lt;- SMOTE(Preeclampsia ~ ., smote_dataset, perc.over = 70, k =5)
table(resampled.training.df$Preeclampsia)

 no yes 
 32  40 </code></pre>
<pre class="r"><code>reweight &lt;- function(pi, q1, r1) {
  r0 &lt;- 1 - r1
  q0 &lt;- 1 - q1
  tot &lt;- pi * (q1 / r1) + (1 - pi) * (q0 / r0)
  w &lt;- pi * (q1 / r1) / tot
  return(w)
}</code></pre>
</div>
<div id="svm-models" class="section level1" number="5">
<h1><span class="header-section-number">5</span> SVM models</h1>
<div id="svmlinearweights-linear-kernel-class-weights" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> svmLinearWeights (linear kernel + class weights)</h2>
<pre class="r"><code>modelLookup(&quot;svmLinearWeights&quot;)
             model parameter        label forReg forClass probModel
1 svmLinearWeights      cost         Cost  FALSE     TRUE      TRUE
2 svmLinearWeights    weight Class Weight  FALSE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(50)

svmgrid &lt;-  expand.grid(cost = c(0.0001, 0.001,0.01,0.1,1,3, 5, 10), weight = c(0.01, 0.05, 0.1,0.5, 0.7,1,5,10))


# training a svm classifier with liearn kernel model while tuning parameters
model = caret::train(Preeclampsia~., data = resampled.training.df,
              method = &quot;svmLinearWeights&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = svmgrid)

# summarizing the results
#print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred1.y &lt;- predict(model, pre17.testing.df1, type = &quot;prob&quot;)[,2]

q1 &lt;- sum(pre17.training.df$Preeclampsia == &quot;yes&quot;) / length(pre17.training.df$Preeclampsia)
r1 &lt;- sum(resampled.training.df$Preeclampsia == &quot;yes&quot;) / length(resampled.training.df$Preeclampsia)

reweighted.probs1 &lt;- sapply(pred1.y, reweight, q1 = q1, r1 = r1)

# out of sample performance metrics
test1.y &lt;- as.numeric(pre17.testing.df1$Preeclampsia) -1

pROC::auc(test1.y, reweighted.probs1, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.4571</code></pre>
<pre class="r"><code>
FNR(reweighted.probs1, test1.y)
     class.pred
truth  0  1
    0 50 11
    1 19  7
[1] 0.7307692</code></pre>
<pre class="r"><code>FPR(reweighted.probs1, test1.y)
     class.pred
truth  0  1
    0 50 11
    1 19  7
[1] 0.1803279</code></pre>
<pre class="r"><code>
roc_SVMlinear_pe_test1 &lt;- ROCit::rocit(score=reweighted.probs1,class=test1.y)</code></pre>
<pre class="r"><code># Add to output
res.testing1 &lt;- rbind.data.frame(res.testing1, c(pROC::auc(test1.y, reweighted.probs1, direction = &quot;&lt;&quot;), FNR(reweighted.probs1, test1.y), FPR(reweighted.probs1, test1.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;SVMLinear&#39;</code></pre>
<pre class="r"><code>#predict on test data
pred2.y &lt;- predict(model, pre17.testing.df2, type = &quot;prob&quot;)[,2]

q1 &lt;- sum(pre17.training.df$Preeclampsia == &quot;yes&quot;) / length(pre17.training.df$Preeclampsia)
r1 &lt;- sum(resampled.training.df$Preeclampsia == &quot;yes&quot;) / length(resampled.training.df$Preeclampsia)

reweighted.probs2 &lt;- sapply(pred2.y, reweight, q1 = q1, r1 = r1)

# out of sample performance metrics
test2.y &lt;- as.numeric(pre17.testing.df2$Preeclampsia) -1

pROC::auc(test2.y, reweighted.probs2, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.5769</code></pre>
<pre class="r"><code>
FNR(reweighted.probs2, test2.y)
     class.pred
truth 0 1
    0 9 4
    1 6 2
[1] 0.75</code></pre>
<pre class="r"><code>FPR(reweighted.probs2, test2.y)
     class.pred
truth 0 1
    0 9 4
    1 6 2
[1] 0.3076923</code></pre>
<pre class="r"><code>
roc_SVMlinear_pe_test2 &lt;- ROCit::rocit(score=reweighted.probs2,class=test2.y)</code></pre>
<pre class="r"><code># Add to output
res.testing2 &lt;- rbind.data.frame(res.testing2, c(pROC::auc(test2.y, reweighted.probs2, direction = &quot;&lt;&quot;), FNR(reweighted.probs2, test2.y), FPR(reweighted.probs2, test2.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;SVMLinear&#39;</code></pre>
</div>
<div id="svmradial-support-vector-machines-with-radial-basis-function-kernel" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> svmRadial (Support Vector Machines with Radial Basis Function Kernel)</h2>
<pre class="r"><code>modelLookup(&quot;svmRadial&quot;)
      model parameter label forReg forClass probModel
1 svmRadial     sigma Sigma   TRUE     TRUE      TRUE
2 svmRadial         C  Cost   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(50)
# Customzing the tuning grid
svmgrid &lt;-  expand.grid(sigma = c(1, 0.1, 0.01, 0.001, 0.0001, 0.00001,0.000001),
                        C = c(0.01,0.1,1, 5, 10, 50, 80, 90, 100, 105, 110, 200, 1000))

# training a svm with rbf kernel classifier model while tuning parameters
model = caret::train(Preeclampsia~., data = resampled.training.df,
              method = &quot;svmRadial&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = svmgrid)

# summarizing the results
#print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred1.y &lt;- predict(model, pre17.testing.df1, type = &quot;prob&quot;)[,2]

q1 &lt;- sum(pre17.training.df$Preeclampsia == &quot;yes&quot;) / length(pre17.training.df$Preeclampsia)
r1 &lt;- sum(resampled.training.df$Preeclampsia == &quot;yes&quot;) / length(resampled.training.df$Preeclampsia)

reweighted.probs1 &lt;- sapply(pred1.y, reweight, q1 = q1, r1 = r1)

# out of sample performance metrics
test1.y &lt;- as.numeric(pre17.testing.df1$Preeclampsia)-1

pROC::auc(test1.y, reweighted.probs1, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.4508</code></pre>
<pre class="r"><code>
FNR(reweighted.probs1, test1.y)
     class.pred
truth  0  1
    0 49 12
    1 19  7
[1] 0.7307692</code></pre>
<pre class="r"><code>FPR(reweighted.probs1, test1.y)
     class.pred
truth  0  1
    0 49 12
    1 19  7
[1] 0.1967213</code></pre>
<pre class="r"><code>
roc_SVMlrbf_pe_test1 &lt;- ROCit::rocit(score=reweighted.probs1,class=test1.y)</code></pre>
<pre class="r"><code># Add to output
res.testing1 &lt;- rbind.data.frame(res.testing1, c(pROC::auc(test1.y, reweighted.probs1, direction = &quot;&lt;&quot;), FNR(reweighted.probs1, test1.y), FPR(reweighted.probs1, test1.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;SVMRadial&#39;</code></pre>
<pre class="r"><code>#predict on test data
pred2.y &lt;- predict(model, pre17.testing.df2, type = &quot;prob&quot;)[,2]

q1 &lt;- sum(pre17.training.df$Preeclampsia == &quot;yes&quot;) / length(pre17.training.df$Preeclampsia)
r1 &lt;- sum(resampled.training.df$Preeclampsia == &quot;yes&quot;) / length(resampled.training.df$Preeclampsia)

reweighted.probs2 &lt;- sapply(pred2.y, reweight, q1 = q1, r1 = r1)

# out of sample performance metrics
test2.y &lt;- as.numeric(pre17.testing.df2$Preeclampsia) -1

pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.5962</code></pre>
<pre class="r"><code>
FNR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 7 6
    1 5 3
[1] 0.625</code></pre>
<pre class="r"><code>FPR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 7 6
    1 5 3
[1] 0.4615385</code></pre>
<pre class="r"><code>
roc_SVMlrbf_pe_test2 &lt;- ROCit::rocit(score=reweighted.probs2,class=test2.y)</code></pre>
<pre class="r"><code># Add to output
res.testing2 &lt;- rbind.data.frame(res.testing2, c(pROC::auc(test2.y, reweighted.probs2, direction = &quot;&lt;&quot;), FNR(reweighted.probs2, test2.y), FPR(reweighted.probs2, test2.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;SVMRadial&#39;</code></pre>
</div>
<div id="svmpoly-support-vector-machines-with-polynomial-kernel" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> svmPoly (Support Vector Machines with Polynomial Kernel)</h2>
<pre class="r"><code>modelLookup(&quot;svmPoly&quot;)
    model parameter             label forReg forClass probModel
1 svmPoly    degree Polynomial Degree   TRUE     TRUE      TRUE
2 svmPoly     scale             Scale   TRUE     TRUE      TRUE
3 svmPoly         C              Cost   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(111)
svmgrid &lt;-  expand.grid(degree = c(2,3,4,5),
                        scale = c(2,3,4,5),
                        C = c(0.001,0.01,0.1,0.5,1,3)
                        )

# training a svm with poly kernel classifier tree model while tuning parameters
model = caret::train(Preeclampsia~., data = resampled.training.df,
              method = &quot;svmPoly&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = svmgrid)

#print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred1.y &lt;- predict(model, pre17.testing.df1, type = &quot;prob&quot;)[,2]

q1 &lt;- sum(pre17.training.df$Preeclampsia == &quot;yes&quot;) / length(pre17.training.df$Preeclampsia)
r1 &lt;- sum(resampled.training.df$Preeclampsia == &quot;yes&quot;) / length(resampled.training.df$Preeclampsia)

reweighted.probs1 &lt;- sapply(pred1.y, reweight, q1 = q1, r1 = r1)

# out of sample performance metrics
test1.y &lt;- as.numeric(pre17.testing.df1$Preeclampsia)-1

pROC::auc(test1.y, reweighted.probs1, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.5631</code></pre>
<pre class="r"><code>
FNR(reweighted.probs1, test1.y)
     class.pred
truth  0  1
    0 51 10
    1 23  3
[1] 0.8846154</code></pre>
<pre class="r"><code>FPR(reweighted.probs1, test1.y)
     class.pred
truth  0  1
    0 51 10
    1 23  3
[1] 0.1639344</code></pre>
<pre class="r"><code>
roc_SVMpoly_pe_test1 &lt;- ROCit::rocit(score=reweighted.probs1,class=test1.y)</code></pre>
<pre class="r"><code># Add to output
res.testing1 &lt;- rbind.data.frame(res.testing1, c(pROC::auc(test1.y, reweighted.probs1, direction = &quot;&lt;&quot;), FNR(reweighted.probs1, test1.y), FPR(reweighted.probs1, test1.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;SVMPoly&#39;</code></pre>
<pre class="r"><code>#predict on test data
pred2.y &lt;- predict(model, pre17.testing.df2, type = &quot;prob&quot;)[,2]

q1 &lt;- sum(pre17.training.df$Preeclampsia == &quot;yes&quot;) / length(pre17.training.df$Preeclampsia)
r1 &lt;- sum(resampled.training.df$Preeclampsia == &quot;yes&quot;) / length(resampled.training.df$Preeclampsia)

reweighted.probs2 &lt;- sapply(pred2.y, reweight, q1 = q1, r1 = r1)

# out of sample performance metrics
test2.y &lt;- as.numeric(pre17.testing.df2$Preeclampsia) -1

pROC::auc(test2.y, reweighted.probs2, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.4519</code></pre>
<pre class="r"><code>
FNR(reweighted.probs2, test2.y)
     class.pred
truth  0  1
    0 10  3
    1  7  1
[1] 0.875</code></pre>
<pre class="r"><code>FPR(reweighted.probs2, test2.y)
     class.pred
truth  0  1
    0 10  3
    1  7  1
[1] 0.2307692</code></pre>
<pre class="r"><code>
roc_SVMpoly_pe_test2 &lt;- ROCit::rocit(score=reweighted.probs2,class=test2.y)</code></pre>
<pre class="r"><code># Add to output
res.testing2 &lt;- rbind.data.frame(res.testing2, c(pROC::auc(test2.y, reweighted.probs2, direction = &quot;&lt;&quot;), FNR(reweighted.probs2, test2.y), FPR(reweighted.probs2, test2.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;SVMPoly&#39;</code></pre>
</div>
</div>
<div id="random-forest" class="section level1" number="6">
<h1><span class="header-section-number">6</span> Random forest</h1>
<pre class="r"><code>modelLookup(&quot;rf&quot;)
  model parameter                         label forReg forClass probModel
1    rf      mtry #Randomly Selected Predictors   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(111)
rfgrid &lt;-  expand.grid(mtry = c(1:18)
                        )
              
# training a randomForest classifier tree model while tuning parameters
model = caret::train(Preeclampsia~., data = pre17.training.df,
              method = &quot;rf&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              importance = T,
              ntree = 80, 
              #maxnodes = 30,
              nodesize = 1, #default for classification
              tuneGrid = rfgrid)

#print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred1.y &lt;- predict(model, pre17.testing.df1, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test1.y &lt;- as.numeric(pre17.testing.df1$Preeclampsia)-1

pROC::auc(test1.y, pred1.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.5473</code></pre>
<pre class="r"><code>
FNR(pred1.y, test1.y)
     class.pred
truth  0  1
    0 37 24
    1 15 11
[1] 0.5769231</code></pre>
<pre class="r"><code>FPR(pred1.y, test1.y)
     class.pred
truth  0  1
    0 37 24
    1 15 11
[1] 0.3934426</code></pre>
<pre class="r"><code>
roc_rf_pe_test1 &lt;- ROCit::rocit(score=pred1.y,class=test1.y)</code></pre>
<pre class="r"><code># Add to output
res.testing1 &lt;- rbind.data.frame(res.testing1, c(pROC::auc(test1.y, pred1.y, direction = &quot;&lt;&quot;), FNR(pred1.y, test1.y), FPR(pred1.y, test1.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;RandomForest&#39;</code></pre>
<pre class="r"><code>#predict on test data
pred2.y &lt;- predict(model, pre17.testing.df2, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test2.y &lt;- as.numeric(pre17.testing.df2$Preeclampsia) -1

pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.3558</code></pre>
<pre class="r"><code>
FNR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 8 5
    1 6 2
[1] 0.75</code></pre>
<pre class="r"><code>FPR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 8 5
    1 6 2
[1] 0.3846154</code></pre>
<pre class="r"><code>
roc_rf_pe_test2 &lt;- ROCit::rocit(score=pred2.y,class=test2.y)</code></pre>
<pre class="r"><code># Add to output
res.testing2 &lt;- rbind.data.frame(res.testing2, c(pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;), FNR(pred2.y, test2.y), FPR(pred2.y, test2.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;RandomForest&#39;</code></pre>
</div>
<div id="elastic-net" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Elastic net</h1>
<pre class="r"><code>modelLookup(&quot;glmnet&quot;)
   model parameter                    label forReg forClass probModel
1 glmnet     alpha        Mixing Percentage   TRUE     TRUE      TRUE
2 glmnet    lambda Regularization Parameter   TRUE     TRUE      TRUE</code></pre>
<pre class="r"><code>train_control = trainControl(method = &quot;cv&quot;, number = 10, search = &quot;grid&quot;,
                             summaryFunction = twoClassSummary,
                             allowParallel = TRUE,
                             # Estimate class probabilities
                             classProbs=TRUE)

set.seed(111)
netgrid &lt;-  expand.grid(alpha = c(0,0.1, 0.2, 0.5, 0.7, 1),lambda = c(0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.5, 0.7,1))

# training a elastic net classifier tree model while tuning parameters
model = caret::train(Preeclampsia~., data = pre17.training.df,
              method = &quot;glmnet&quot;,
              trControl = train_control,
              metric = &quot;ROC&quot;,
              tuneGrid = netgrid)

# summarizing the results
#print(model)</code></pre>
<pre class="r"><code>#predict on test data
pred1.y &lt;- predict(model, pre17.testing.df1, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test1.y &lt;- as.numeric(pre17.testing.df1$Preeclampsia)-1

pROC::auc(test1.y, pred1.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.5126</code></pre>
<pre class="r"><code>
FNR(pred1.y, test1.y)
     class.pred
truth  0  1
    0 49 12
    1 20  6
[1] 0.7692308</code></pre>
<pre class="r"><code>FPR(pred1.y, test1.y)
     class.pred
truth  0  1
    0 49 12
    1 20  6
[1] 0.1967213</code></pre>
<pre class="r"><code>
roc_elastic_pe_test1 &lt;- ROCit::rocit(score=pred1.y,class=test1.y)</code></pre>
<pre class="r"><code># Add to output
res.testing1 &lt;- rbind.data.frame(res.testing1, c(pROC::auc(test1.y, pred1.y, direction = &quot;&lt;&quot;), FNR(pred1.y, test1.y), FPR(pred1.y, test1.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;ElasticNet&#39;</code></pre>
<pre class="r"><code>#predict on test data
pred2.y &lt;- predict(model, pre17.testing.df2, type = &quot;prob&quot;)[,2]

# out of sample performance metrics
test2.y &lt;- as.numeric(pre17.testing.df2$Preeclampsia) -1

pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.5288</code></pre>
<pre class="r"><code>
FNR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 7 6
    1 6 2
[1] 0.75</code></pre>
<pre class="r"><code>FPR(pred2.y, test2.y)
     class.pred
truth 0 1
    0 7 6
    1 6 2
[1] 0.4615385</code></pre>
<pre class="r"><code>
roc_elastic_pe_test2 &lt;- ROCit::rocit(score=pred2.y,class=test2.y)</code></pre>
<pre class="r"><code># Add to output
res.testing2 &lt;- rbind.data.frame(res.testing2, c(pROC::auc(test2.y, pred2.y, direction = &quot;&lt;&quot;), FNR(pred2.y, test2.y), FPR(pred2.y, test2.y)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;ElasticNet&#39;</code></pre>
</div>
<div id="keras-nn" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Keras NN</h1>
<pre class="r"><code>library(tensorflow)

Attaching package: &#39;tensorflow&#39;
The following object is masked from &#39;package:caret&#39;:

    train</code></pre>
<pre class="r"><code>library(keras)

Attaching package: &#39;keras&#39;
The following object is masked from &#39;package:BiocGenerics&#39;:

    normalize</code></pre>
<pre class="r"><code>library(tfruns)
tensorflow::set_random_seed(111)</code></pre>
<pre class="r"><code>x_train &lt;- as.matrix(pre17.training.df[,-1])
y_train &lt;- as.matrix(as.numeric(pre17.training.df$Preeclampsia)-1)

x_test1&lt;- as.matrix(pre17.testing.df1[,-1])
y_test1 &lt;- as.matrix(as.numeric(pre17.testing.df1$Preeclampsia)-1)

x_test2&lt;- as.matrix(pre17.testing.df2[,-1])
y_test2 &lt;- as.matrix(as.numeric(pre17.testing.df2$Preeclampsia)-1)

x_train_shape &lt;- length(colnames(x_train))</code></pre>
<pre class="r"><code>model &lt;- keras_model_sequential()
model %&gt;%
  layer_dense(units = 1000, activation = &#39;relu&#39;,
              input_shape = c(x_train_shape),
              kernel_regularizer = regularizer_l1_l2(l1 = 0.0000001, l2 = 0.000001),
              bias_regularizer = regularizer_l1_l2(l1 = 0.00001, l2 = 0.0001),
              kernel_constraint =constraint_maxnorm(max_value = 2, axis = 0),
              #bias_constraint =constraint_maxnorm(max_value = 3, axis = 0),
              activity_regularizer= regularizer_l1_l2(l1 = 0.01, l2 = 0.00001),
              ) %&gt;%  
  layer_dropout(rate = 0.7) %&gt;% 
  layer_batch_normalization() %&gt;%
  layer_dense(units = 350, activation = &#39;relu&#39;,
              kernel_regularizer = regularizer_l1_l2(l1 = 0.1, l2 = 0.1),
              kernel_constraint = constraint_minmaxnorm(max_value = 2, min_value = 0, axis = 1),
              bias_regularizer = regularizer_l1_l2(l1 = 0.00001, l2 = 0.000001),
              #bias_constraint =constraint_maxnorm(max_value = 3, axis = 0),
              activity_regularizer = regularizer_l1_l2(l1 = 0.1, l2 = 0.000001),
              ) %&gt;%
  layer_dropout(rate = 0.3) %&gt;%
  layer_batch_normalization() %&gt;%
  layer_dense(units = 125, activation = &#39;relu&#39;,
              kernel_regularizer = regularizer_l1_l2(l1 = 0.01, l2 = 0.01),
              kernel_constraint = constraint_minmaxnorm(max_value = 2, min_value = 0, axis = 1),
              #bias_regularizer = regularizer_l1_l2(l1 = 0.00001, l2 = 0.000001),
              #bias_constraint =constraint_maxnorm(max_value = 3, axis = 0),
              activity_regularizer = regularizer_l1_l2(l1 = 0.001, l2 = 0.000001),
              ) %&gt;%
  layer_dropout(rate = 0.3) %&gt;%
  layer_batch_normalization() %&gt;%
  layer_dense(units = 1, activation = &#39;sigmoid&#39;)</code></pre>
<pre class="r"><code>loss_fn &lt;- loss_binary_crossentropy()
auc &lt;- metric_auc()
adam &lt;- optimizer_adam(learning_rate = 0.0001, ema_momentum = 0.8)

model %&gt;% compile(
  optimizer = adam,
  loss = loss_fn,
  metrics = &quot;AUC&quot;
)</code></pre>
<pre class="r"><code>model %&gt;% fit(x_train, y_train, epochs = 75, batch_size =3)</code></pre>
<p>TESTING 1</p>
<pre class="r"><code>model %&gt;% evaluate(x_test1,  y_test1, verbose = 2)
3/3 - 0s - loss: 17.2937 - auc: 0.7071 - 230ms/epoch - 77ms/step
      loss        auc 
17.2936935  0.7071249 </code></pre>
<p>TESTING 2</p>
<pre class="r"><code>model %&gt;% evaluate(x_test2,  y_test2, verbose = 2)
1/1 - 0s - loss: 21.4332 - auc: 0.4135 - 14ms/epoch - 14ms/step
      loss        auc 
21.4331818  0.4134615 </code></pre>
<pre class="r"><code>b.1&lt;-model %&gt;% predict(x_test1) #%&gt;% `&gt;`(0.5) %&gt;% k_cast(&quot;int32&quot;) 
3/3 - 0s - 75ms/epoch - 25ms/step</code></pre>
<pre class="r"><code>b.1 &lt;- as.numeric(b.1)

b.2&lt;-model %&gt;% predict(x_test2) #%&gt;% `&gt;`(0.5) %&gt;% k_cast(&quot;int32&quot;) 
1/1 - 0s - 10ms/epoch - 10ms/step</code></pre>
<pre class="r"><code>b.2 &lt;- as.numeric(b.2)</code></pre>
<p>Testing 1</p>
<pre class="r"><code>pROC::auc(as.numeric(y_test1), b.1, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.7037</code></pre>
<pre class="r"><code>
FNR(b.1, y_test1)
     class.pred
truth  0  1
    0 38 23
    1  7 19
[1] 0.2692308</code></pre>
<pre class="r"><code>FPR(b.1, y_test1)
     class.pred
truth  0  1
    0 38 23
    1  7 19
[1] 0.3770492</code></pre>
<pre class="r"><code>
roc_nnet_pe_test1 &lt;- ROCit::rocit(score=b.1,class=as.numeric(y_test1))</code></pre>
<pre class="r"><code># Add to output
res.testing1 &lt;- rbind.data.frame(res.testing1, c(pROC::auc(as.numeric(y_test1), b.1), FNR(b.1, y_test1), FPR(b.1, y_test1)))
Setting levels: control = 0, case = 1
Setting direction: controls &lt; cases</code></pre>
<pre class="r"><code>rownames(res.testing1)[nrow(res.testing1)] &lt;- &#39;KerasNN&#39;</code></pre>
<p>Testing 2</p>
<pre class="r"><code>pROC::auc(as.numeric(y_test2), b.2, direction = &quot;&lt;&quot;)
Setting levels: control = 0, case = 1
Area under the curve: 0.3846</code></pre>
<pre class="r"><code>
FNR(b.2, y_test2)
     class.pred
truth 0 1
    0 8 5
    1 6 2
[1] 0.75</code></pre>
<pre class="r"><code>FPR(b.2, y_test2)
     class.pred
truth 0 1
    0 8 5
    1 6 2
[1] 0.3846154</code></pre>
<pre class="r"><code>
roc_nnet_pe_test2 &lt;- ROCit::rocit(score=b.2,class=as.numeric(y_test2))</code></pre>
<pre class="r"><code># Add to output
res.testing2 &lt;- rbind.data.frame(res.testing2, c(pROC::auc(as.numeric(y_test2), b.2,  direction = &quot;&lt;&quot;), FNR(b.2, y_test2), FPR(b.2, y_test2)))
Setting levels: control = 0, case = 1</code></pre>
<pre class="r"><code>rownames(res.testing2)[nrow(res.testing2)] &lt;- &#39;KerasNN&#39;</code></pre>
</div>
<div id="roc-auc-curve-for-all-models" class="section level1" number="9">
<h1><span class="header-section-number">9</span> ROC-AUC curve for all models</h1>
<p>Testing 1</p>
<p><img src="05_pr_pe_files/figure-html/unnamed-chunk-85-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
<p>Testing 2</p>
<p><img src="05_pr_pe_files/figure-html/unnamed-chunk-86-1.png" width="100%"  class="widefigure" style="display: block; margin: auto;" /></p>
</div>
<div id="model-perfomancesresults-in-tables" class="section level1" number="10">
<h1><span class="header-section-number">10</span> Model perfomances/results in tables</h1>
<pre class="r"><code>(res.testing1)
                   AUC       FNR        FPR
XGBOOST      0.6478562 0.7307692 0.08196721
SVMLinear    0.4571248 0.7307692 0.18032787
SVMRadial    0.4508197 0.7307692 0.19672131
SVMPoly      0.5630517 0.8846154 0.16393443
RandomForest 0.5472888 0.5769231 0.39344262
ElasticNet   0.5126103 0.7692308 0.19672131
KerasNN      0.7036570 0.2692308 0.37704918</code></pre>
<pre class="r"><code>(res.testing2)
                   AUC   FNR       FPR
XGBOOST      0.3365385 0.875 0.3846154
SVMLinear    0.5769231 0.750 0.3076923
SVMRadial    0.5961538 0.750 0.3076923
SVMPoly      0.4519231 0.875 0.2307692
RandomForest 0.3557692 0.750 0.3846154
ElasticNet   0.5288462 0.750 0.4615385
KerasNN      0.3846154 0.750 0.3846154</code></pre>
</div>
<div id="session-information" class="section level1" number="11">
<h1><span class="header-section-number">11</span> Session information</h1>
<pre class="r"><code>sessionInfo()
R version 4.4.0 (2024-04-24)
Platform: x86_64-pc-linux-gnu
Running under: Ubuntu 22.04.4 LTS

Matrix products: default
BLAS:   /usr/lib/x86_64-linux-gnu/blas/libblas.so.3.10.0 
LAPACK: /usr/lib/x86_64-linux-gnu/lapack/liblapack.so.3.10.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=es_ES.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=es_ES.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=es_ES.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=es_ES.UTF-8 LC_IDENTIFICATION=C       

time zone: Europe/Madrid
tzcode source: system (glibc)

attached base packages:
[1] grid      stats4    stats     graphics  grDevices utils     datasets 
[8] methods   base     

other attached packages:
 [1] tfruns_1.5.3                keras_2.15.0               
 [3] tensorflow_2.16.0.9000      DMwR_0.4.1                 
 [5] dplyr_1.1.4                 edgeR_4.2.0                
 [7] limma_3.60.2                SummarizedExperiment_1.34.0
 [9] Biobase_2.64.0              GenomicRanges_1.56.0       
[11] GenomeInfoDb_1.40.1         IRanges_2.38.0             
[13] S4Vectors_0.42.0            BiocGenerics_0.50.0        
[15] MatrixGenerics_1.16.0       matrixStats_1.3.0          
[17] caret_6.0-94                lattice_0.22-5             
[19] ggplot2_3.5.1               kableExtra_1.4.0           
[21] knitr_1.46                  BiocStyle_2.32.0           

loaded via a namespace (and not attached):
  [1] rstudioapi_0.16.0       jsonlite_1.8.8          shape_1.4.6            
  [4] magrittr_2.0.3          rmarkdown_2.27          zlibbioc_1.50.0        
  [7] vctrs_0.6.5             ROCR_1.0-11             base64enc_0.1-3        
 [10] tinytex_0.49            htmltools_0.5.8.1       S4Arrays_1.4.1         
 [13] curl_5.2.1              xgboost_1.7.7.1         SparseArray_1.4.8      
 [16] pROC_1.18.5             TTR_0.24.4              sass_0.4.9             
 [19] parallelly_1.36.0       bslib_0.7.0             plyr_1.8.9             
 [22] zoo_1.8-12              lubridate_1.9.3         cachem_1.0.8           
 [25] whisker_0.4.1           lifecycle_1.0.4         iterators_1.0.14       
 [28] pkgconfig_2.0.3         Matrix_1.6-5            R6_2.5.1               
 [31] fastmap_1.2.0           GenomeInfoDbData_1.2.12 future_1.33.1          
 [34] digest_0.6.35           colorspace_2.1-0        rprojroot_2.0.4        
 [37] randomForest_4.7-1.1    fansi_1.0.6             timechange_0.3.0       
 [40] httr_1.4.7              abind_1.4-5             compiler_4.4.0         
 [43] here_1.0.1              proxy_0.4-27            withr_3.0.0            
 [46] ROCit_2.1.2             highr_0.9               MASS_7.3-60.0.1        
 [49] lava_1.7.3              rappdirs_0.3.3          DelayedArray_0.30.1    
 [52] ModelMetrics_1.2.2.2    tools_4.4.0             quantmod_0.4.26        
 [55] future.apply_1.11.1     nnet_7.3-19             glue_1.7.0             
 [58] nlme_3.1-163            reshape2_1.4.4          generics_0.1.3         
 [61] recipes_1.0.10          gtable_0.3.4            class_7.3-22           
 [64] data.table_1.15.0       xml2_1.3.6              utf8_1.2.4             
 [67] XVector_0.44.0          foreach_1.5.2           pillar_1.9.0           
 [70] stringr_1.5.1           splines_4.4.0           survival_3.5-8         
 [73] tidyselect_1.2.1        locfit_1.5-9.9          bookdown_0.39          
 [76] svglite_2.1.3           xfun_0.44               statmod_1.4.37         
 [79] hardhat_1.3.1           timeDate_4032.109       stringi_1.8.3          
 [82] UCSC.utils_1.0.0        yaml_2.3.8              evaluate_0.23          
 [85] codetools_0.2-19        kernlab_0.9-32          tibble_3.2.1           
 [88] BiocManager_1.30.23     cli_3.6.2               rpart_4.1.23           
 [91] reticulate_1.37.0       systemfonts_1.0.5       munsell_0.5.0          
 [94] jquerylib_0.1.4         Rcpp_1.0.12             globals_0.16.2         
 [97] zeallot_0.1.0           png_0.1-8               parallel_4.4.0         
[100] gower_1.0.0             listenv_0.9.1           glmnet_4.1-8           
[103] viridisLite_0.4.2       ipred_0.9-14            scales_1.3.0           
[106] xts_0.13.2              prodlim_2023.08.28      e1071_1.7-14           
[109] purrr_1.0.2             crayon_1.5.2            rlang_1.1.3            </code></pre>
</div>
<div id="references" class="section level1 unnumbered">
<h1>References</h1>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-delvecchio2021cell" class="csl-entry">
Del Vecchio, Giorgia, Qingjiao Li, Wenyuan Li, Shanthie Thamotharan, Anela Tosevska, Marco Morselli, Kyunghyun Sung, et al. 2021. <span>‚ÄúCell-Free DNA Methylation and Transcriptomic Signature Prediction of Pregnancies with Adverse Outcomes.‚Äù</span> <em>Epigenetics</em> 16 (6): 642‚Äì61.
</div>
<div id="ref-moufarrej2022early" class="csl-entry">
Moufarrej, Mira N, Sevahn K Vorperian, Ronald J Wong, Ana A Campos, Cecele C Quaintance, Rene V Sit, Michelle Tan, et al. 2022. <span>‚ÄúEarly Prediction of Preeclampsia in Pregnancy with Cell-Free RNA.‚Äù</span> <em>Nature</em> 602 (7898): 689‚Äì94.
</div>
<div id="ref-Roskams2022" class="csl-entry">
Roskams-Hieter, Breeshey, Hyun Ji Kim, Pavana Anur, Josiah T. Wagner, Rowan Callahan, Elias Spiliotopoulos, Charles Ward Kirschbaum, et al. 2022. <span>‚ÄúPlasma Cell-Free RNA Profiling Distinguishes Cancers from Pre-Malignant Conditions in Solid and Hematologic Malignancies.‚Äù</span> <em>Npj Precision Oncology</em> 6. <a href="https://doi.org/10.1038/s41698-022-00270-y">https://doi.org/10.1038/s41698-022-00270-y</a>.
</div>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    "HTML-CSS": {
      styles: {
        ".MathJax_Display": {
           "text-align": "center",
           padding: "0px 150px 0px 65px",
           margin: "0px 0px 0.5em"
        },
        "@media screen and (max-width: 991px)": {
            ".MathJax_Display": {
               "text-align": "center",
               padding: "0 0 0 0"
            }
         }
      }
    }
  });
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<script type="text/javascript">
$(document).ready(function ()  {
  
  // Map "enter" keypress to the same action as a cursor click
  function navigateLink(e) {
    if (e.key === "Enter") {
      $(this).trigger("click");
    }
  }

  var toc_items = document.querySelectorAll(".tocify-item");
  for (var i = 0; i < toc_items.length; i++) {
    // The link role tells screen readers this is for navigation
    toc_items.item(i).setAttribute("role", "link");
    // tabindex = 0 allows selection via keyboard tab presses
    toc_items.item(i).setAttribute("tabindex", "0");
    // Listen for "Enter" keypress when item is selected
    toc_items.item(i).addEventListener("keydown", navigateLink);
  }
});
</script>

</body>
</html>
